```markdown
# âš–ï¸ AutoLawyer â€“ Multi-Agent AI for Legal Case Drafting

AutoLawyer is a full-stack, offline-first LegalTech platform that uses **multi-agent AI systems** powered by **GPT4All (local LLMs)** to automate the drafting of legal briefs. Designed for legal professionals, students, and researchers, it simulates a legal team by coordinating **research**, **drafting**, and **summarization** agents in a LangGraph workflow.

> ğŸ” 100% Local. No OpenAI or external APIs. Secure. Private. Cost-free AI.

---

## ğŸ§  Multi-Agent Workflow

| Agent       | Role                                                                 |
|-------------|----------------------------------------------------------------------|
| ğŸ§  Researcher   | Gathers legal precedents, statutes, and relevant case law       |
| âœï¸ Drafter     | Converts research into formal legal arguments                    |
| ğŸ“„ Summarizer  | Summarizes the draft into bullet points or executive summary    |

---

## ğŸ›  Tech Stack

### ğŸ§  AI
- **LLM**: `GPT4All` using [`Nous Hermes 2 Mistral 7B - Q4_0` GGUF model](https://huggingface.co/TheBloke/Nous-Hermes-2-Mistral-7B-DPO-GGUF)
- **LangGraph**: Defines the AI agent flow

### âš™ Backend
- **FastAPI**: REST API and agent controller
- **SQLAlchemy**: ORM for DB models
- **Pydantic**: Data validation

### ğŸ–¥ Frontend
- **Next.js (TypeScript)**: Web interface
- **Tailwind CSS**: Styling
- **React Quill or TipTap**: Collaborative legal editor

### ğŸ—„ Database
- SQLite (default) or PostgreSQL for production use

---

## ğŸ“‚ Project Structure

```

autolawyer/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ agents/             # researcher.py, drafter.py, summarizer.py
â”‚   â”œâ”€â”€ core/               # LangGraph DAG, prompt templates, runner
â”‚   â”œâ”€â”€ local\_llm/          # GPT4All runner + config
â”‚   â”œâ”€â”€ db/                 # SQLAlchemy models and DB setup
â”‚   â”œâ”€â”€ routes/             # API endpoints (briefs, agents, users)
â”‚   â””â”€â”€ main.py             # FastAPI app entrypoint
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ components/         # Editor, AgentView, BriefList
â”‚   â”œâ”€â”€ pages/              # index.tsx, brief/\[id].tsx
â”‚   â””â”€â”€ utils/              # api.ts, formatter.ts
â”‚
â”œâ”€â”€ models/                 # Downloaded GGUF model goes here
â”œâ”€â”€ .env.local              # Local configuration
â”œâ”€â”€ README.md               # This file
â””â”€â”€ run\_backend.sh          # Start script for backend and model

````

---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Clone the Repo

```bash
git clone https://github.com/yourusername/AutoLawyer.git
cd AutoLawyer
````

### 2ï¸âƒ£ Download the LLM Model

Download this model file:

> `Nous-Hermes-2-Mistral-7B-DPO.Q4_0.gguf`

Place it in:

```
models/Nous-Hermes-2-Mistral-7B-DPO.Q4_0.gguf
```

### 3ï¸âƒ£ Backend Setup (Python 3.10+)

```bash
cd backend
pip install -r requirements.txt
uvicorn main:app --reload
```

### 4ï¸âƒ£ Frontend Setup (Node.js 18+)

```bash
cd frontend
npm install
npm run dev
```

---

## ğŸŒ Features

* ğŸ§  Local GPT4All-powered legal brief generation
* ğŸ§© Modular LangGraph agent design
* ğŸ“„ Rich-text legal editor with agent insertions
* ğŸ“œ Version-controlled brief logs + full history
* ğŸ›  Easy agent customization (just swap the file!)
* ğŸ” 100% offline: No API keys, no cloud

---

## âš™ï¸ Model Config (backend/local\_llm/model\_config.json)

```json
{
  "model_path": "models/Nous-Hermes-2-Mistral-7B-DPO.Q4_0.gguf",
  "context_size": 4096,
  "temperature": 0.7
}
```

---

## ğŸ§  Example Use Case

1. Create a new brief
2. Trigger the **researcher agent**
3. Review the extracted legal content
4. Trigger the **drafter** to generate arguments
5. Finalize using the **summarizer**
6. Edit, save, or export your draft

---

## ğŸ›¡ License

MIT License. No AI-generated content should be considered legal advice.

---

